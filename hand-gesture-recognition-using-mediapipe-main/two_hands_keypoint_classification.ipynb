{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/two_hands_keypoint_classifier/two_hands_keypoint.csv'\n",
    "model_save_path = 'model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2 * 2, )),\n",
    "    tf.keras.layers.Dense(80, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 80)                6800      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 40)                3240      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 40)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11125 (43.46 KB)\n",
      "Trainable params: 11125 (43.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/23 [=======================>......] - ETA: 0s - loss: 55.4066 - accuracy: 0.2418  \n",
      "Epoch 1: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 2s 13ms/step - loss: 49.0751 - accuracy: 0.2599 - val_loss: 2.8338 - val_accuracy: 0.5015\n",
      "Epoch 2/1000\n",
      "18/23 [======================>.......] - ETA: 0s - loss: 9.8831 - accuracy: 0.4062 \n",
      "Epoch 2: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 9.2425 - accuracy: 0.4204 - val_loss: 1.1405 - val_accuracy: 0.7688\n",
      "Epoch 3/1000\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 6.4023 - accuracy: 0.4062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/myenv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/23 [=======================>......] - ETA: 0s - loss: 4.9740 - accuracy: 0.5082\n",
      "Epoch 3: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 4.8091 - accuracy: 0.5096 - val_loss: 0.2697 - val_accuracy: 0.8931\n",
      "Epoch 4/1000\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 2.8720 - accuracy: 0.5836\n",
      "Epoch 4: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2.7929 - accuracy: 0.5909 - val_loss: 0.1537 - val_accuracy: 0.9784\n",
      "Epoch 5/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 2.3498 - accuracy: 0.5979\n",
      "Epoch 5: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 2.2031 - accuracy: 0.6135 - val_loss: 0.1716 - val_accuracy: 0.9918\n",
      "Epoch 6/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 1.8652 - accuracy: 0.6672\n",
      "Epoch 6: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.7423 - accuracy: 0.6752 - val_loss: 0.1210 - val_accuracy: 0.9969\n",
      "Epoch 7/1000\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 1.1915 - accuracy: 0.7184\n",
      "Epoch 7: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1.2545 - accuracy: 0.7154 - val_loss: 0.0866 - val_accuracy: 0.9959\n",
      "Epoch 8/1000\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 1.2001 - accuracy: 0.7377\n",
      "Epoch 8: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.1828 - accuracy: 0.7404 - val_loss: 0.0570 - val_accuracy: 0.9959\n",
      "Epoch 9/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.7923 - accuracy: 0.7719\n",
      "Epoch 9: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.8730 - accuracy: 0.7654 - val_loss: 0.0447 - val_accuracy: 0.9979\n",
      "Epoch 10/1000\n",
      "13/23 [===============>..............] - ETA: 0s - loss: 0.8780 - accuracy: 0.7620\n",
      "Epoch 10: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.8472 - accuracy: 0.7709 - val_loss: 0.0523 - val_accuracy: 0.9979\n",
      "Epoch 11/1000\n",
      "12/23 [==============>...............] - ETA: 0s - loss: 0.7819 - accuracy: 0.7839\n",
      "Epoch 11: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.7250 - accuracy: 0.8001 - val_loss: 0.0386 - val_accuracy: 0.9979\n",
      "Epoch 12/1000\n",
      "16/23 [===================>..........] - ETA: 0s - loss: 0.7114 - accuracy: 0.8022\n",
      "Epoch 12: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.6755 - accuracy: 0.8069 - val_loss: 0.0270 - val_accuracy: 0.9979\n",
      "Epoch 13/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.5705 - accuracy: 0.8359\n",
      "Epoch 13: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5784 - accuracy: 0.8392 - val_loss: 0.0306 - val_accuracy: 0.9979\n",
      "Epoch 14/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.5357 - accuracy: 0.8504\n",
      "Epoch 14: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.5234 - accuracy: 0.8471 - val_loss: 0.0270 - val_accuracy: 0.9979\n",
      "Epoch 15/1000\n",
      "16/23 [===================>..........] - ETA: 0s - loss: 0.4812 - accuracy: 0.8413\n",
      "Epoch 15: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.5068 - accuracy: 0.8405 - val_loss: 0.0216 - val_accuracy: 0.9979\n",
      "Epoch 16/1000\n",
      "16/23 [===================>..........] - ETA: 0s - loss: 0.4830 - accuracy: 0.8594\n",
      "Epoch 16: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.8625 - val_loss: 0.0211 - val_accuracy: 0.9979\n",
      "Epoch 17/1000\n",
      "16/23 [===================>..........] - ETA: 0s - loss: 0.4963 - accuracy: 0.8848\n",
      "Epoch 17: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4745 - accuracy: 0.8789 - val_loss: 0.0093 - val_accuracy: 0.9979\n",
      "Epoch 18/1000\n",
      "16/23 [===================>..........] - ETA: 0s - loss: 0.3835 - accuracy: 0.8848\n",
      "Epoch 18: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4055 - accuracy: 0.8786 - val_loss: 0.0063 - val_accuracy: 0.9990\n",
      "Epoch 19/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.3655 - accuracy: 0.8885\n",
      "Epoch 19: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8844 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.4070 - accuracy: 0.8823\n",
      "Epoch 20: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3808 - accuracy: 0.8844 - val_loss: 0.0109 - val_accuracy: 0.9979\n",
      "Epoch 21/1000\n",
      "13/23 [===============>..............] - ETA: 0s - loss: 0.3843 - accuracy: 0.8978\n",
      "Epoch 21: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3776 - accuracy: 0.8951 - val_loss: 0.0108 - val_accuracy: 0.9979\n",
      "Epoch 22/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.4031 - accuracy: 0.9036\n",
      "Epoch 22: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3799 - accuracy: 0.8992 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
      "Epoch 23/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.3304 - accuracy: 0.9001\n",
      "Epoch 23: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3045 - accuracy: 0.9088 - val_loss: 0.0103 - val_accuracy: 0.9979\n",
      "Epoch 24/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.3300 - accuracy: 0.8943\n",
      "Epoch 24: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3207 - accuracy: 0.8978 - val_loss: 0.0134 - val_accuracy: 0.9979\n",
      "Epoch 25/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.3419 - accuracy: 0.9180\n",
      "Epoch 25: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3207 - accuracy: 0.9187 - val_loss: 0.0138 - val_accuracy: 0.9979\n",
      "Epoch 26/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.2978 - accuracy: 0.9074\n",
      "Epoch 26: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.2948 - accuracy: 0.9119 - val_loss: 0.0071 - val_accuracy: 0.9979\n",
      "Epoch 27/1000\n",
      "13/23 [===============>..............] - ETA: 0s - loss: 0.2488 - accuracy: 0.9285\n",
      "Epoch 27: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2459 - accuracy: 0.9246 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
      "Epoch 28/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.3024 - accuracy: 0.9191\n",
      "Epoch 28: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2894 - accuracy: 0.9174 - val_loss: 0.0026 - val_accuracy: 0.9990\n",
      "Epoch 29/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.3421 - accuracy: 0.9247\n",
      "Epoch 29: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3103 - accuracy: 0.9211 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.9139\n",
      "Epoch 30: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2767 - accuracy: 0.9139 - val_loss: 9.9305e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "16/23 [===================>..........] - ETA: 0s - loss: 0.2044 - accuracy: 0.9375\n",
      "Epoch 31: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2039 - accuracy: 0.9366 - val_loss: 0.0018 - val_accuracy: 0.9990\n",
      "Epoch 32/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.2846 - accuracy: 0.9276\n",
      "Epoch 32: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2869 - accuracy: 0.9249 - val_loss: 0.0014 - val_accuracy: 0.9990\n",
      "Epoch 33/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.2313 - accuracy: 0.9297\n",
      "Epoch 33: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2513 - accuracy: 0.9242 - val_loss: 9.1797e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "13/23 [===============>..............] - ETA: 0s - loss: 0.2361 - accuracy: 0.9279\n",
      "Epoch 34: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2116 - accuracy: 0.9331 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
      "Epoch 35/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1879 - accuracy: 0.9336\n",
      "Epoch 35: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1951 - accuracy: 0.9352 - val_loss: 0.0016 - val_accuracy: 0.9990\n",
      "Epoch 36/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.2040 - accuracy: 0.9358\n",
      "Epoch 36: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1966 - accuracy: 0.9420 - val_loss: 5.8959e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.2687 - accuracy: 0.9354\n",
      "Epoch 37: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2640 - accuracy: 0.9352 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1858 - accuracy: 0.9380\n",
      "Epoch 38: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.2059 - accuracy: 0.9379 - val_loss: 5.1705e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "13/23 [===============>..............] - ETA: 0s - loss: 0.1684 - accuracy: 0.9489\n",
      "Epoch 39: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1741 - accuracy: 0.9451 - val_loss: 0.0013 - val_accuracy: 0.9990\n",
      "Epoch 40/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1730 - accuracy: 0.9443\n",
      "Epoch 40: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1735 - accuracy: 0.9458 - val_loss: 8.4689e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1817 - accuracy: 0.9442\n",
      "Epoch 41: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1934 - accuracy: 0.9472 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
      "Epoch 42/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1800 - accuracy: 0.9490\n",
      "Epoch 42: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1825 - accuracy: 0.9479 - val_loss: 5.3751e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1686 - accuracy: 0.9459\n",
      "Epoch 43: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1779 - accuracy: 0.9472 - val_loss: 6.6661e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "16/23 [===================>..........] - ETA: 0s - loss: 0.1510 - accuracy: 0.9590\n",
      "Epoch 44: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1512 - accuracy: 0.9595 - val_loss: 0.0067 - val_accuracy: 0.9990\n",
      "Epoch 45/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1620 - accuracy: 0.9537\n",
      "Epoch 45: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1551 - accuracy: 0.9561 - val_loss: 0.0090 - val_accuracy: 0.9990\n",
      "Epoch 46/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1777 - accuracy: 0.9557\n",
      "Epoch 46: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1938 - accuracy: 0.9482 - val_loss: 0.0015 - val_accuracy: 0.9990\n",
      "Epoch 47/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1467 - accuracy: 0.9570\n",
      "Epoch 47: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1534 - accuracy: 0.9564 - val_loss: 3.2414e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1333 - accuracy: 0.9637\n",
      "Epoch 48: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1502 - accuracy: 0.9558 - val_loss: 2.0967e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1523 - accuracy: 0.9531\n",
      "Epoch 49: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.1420 - accuracy: 0.9554 - val_loss: 1.1091e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "13/23 [===============>..............] - ETA: 0s - loss: 0.1580 - accuracy: 0.9597\n",
      "Epoch 50: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1676 - accuracy: 0.9551 - val_loss: 8.2244e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1502 - accuracy: 0.9630\n",
      "Epoch 51: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1471 - accuracy: 0.9609 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
      "Epoch 52/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1086 - accuracy: 0.9661\n",
      "Epoch 52: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1221 - accuracy: 0.9636 - val_loss: 0.0014 - val_accuracy: 0.9990\n",
      "Epoch 53/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1366 - accuracy: 0.9583\n",
      "Epoch 53: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1373 - accuracy: 0.9592 - val_loss: 3.7018e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "16/23 [===================>..........] - ETA: 0s - loss: 0.1329 - accuracy: 0.9604\n",
      "Epoch 54: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.9578 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 55/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1356 - accuracy: 0.9665\n",
      "Epoch 55: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1362 - accuracy: 0.9636 - val_loss: 0.0057 - val_accuracy: 0.9990\n",
      "Epoch 56/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1071 - accuracy: 0.9648\n",
      "Epoch 56: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1080 - accuracy: 0.9643 - val_loss: 2.0932e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1326 - accuracy: 0.9620\n",
      "Epoch 57: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1527 - accuracy: 0.9626 - val_loss: 2.3220e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1411 - accuracy: 0.9654\n",
      "Epoch 58: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1376 - accuracy: 0.9681 - val_loss: 5.3748e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1113 - accuracy: 0.9714\n",
      "Epoch 59: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1113 - accuracy: 0.9709 - val_loss: 5.8201e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.0970 - accuracy: 0.9724\n",
      "Epoch 60: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.1190 - accuracy: 0.9698 - val_loss: 5.9329e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1161 - accuracy: 0.9661\n",
      "Epoch 61: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1067 - accuracy: 0.9695 - val_loss: 2.4419e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1180 - accuracy: 0.9626\n",
      "Epoch 62: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1191 - accuracy: 0.9619 - val_loss: 0.0192 - val_accuracy: 0.9990\n",
      "Epoch 63/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1000 - accuracy: 0.9703\n",
      "Epoch 63: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1107 - accuracy: 0.9691 - val_loss: 1.6067e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1125 - accuracy: 0.9621\n",
      "Epoch 64: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1170 - accuracy: 0.9636 - val_loss: 2.7460e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1108 - accuracy: 0.9665\n",
      "Epoch 65: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1073 - accuracy: 0.9667 - val_loss: 3.3933e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "16/23 [===================>..........] - ETA: 0s - loss: 0.1124 - accuracy: 0.9673\n",
      "Epoch 66: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1103 - accuracy: 0.9678 - val_loss: 5.5889e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1161 - accuracy: 0.9776\n",
      "Epoch 67: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1070 - accuracy: 0.9757 - val_loss: 8.8785e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1415 - accuracy: 0.9715\n",
      "Epoch 68: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1292 - accuracy: 0.9702 - val_loss: 1.1063e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "13/23 [===============>..............] - ETA: 0s - loss: 0.1046 - accuracy: 0.9712\n",
      "Epoch 69: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 0.9746 - val_loss: 2.0046e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "13/23 [===============>..............] - ETA: 0s - loss: 0.1068 - accuracy: 0.9651\n",
      "Epoch 70: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0983 - accuracy: 0.9671 - val_loss: 2.0973e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.1115 - accuracy: 0.9723\n",
      "Epoch 71: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.1063 - accuracy: 0.9736 - val_loss: 1.8406e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "17/23 [=====================>........] - ETA: 0s - loss: 0.1175 - accuracy: 0.9692\n",
      "Epoch 72: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1239 - accuracy: 0.9664 - val_loss: 2.8688e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.1010 - accuracy: 0.9677\n",
      "Epoch 73: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0944 - accuracy: 0.9705 - val_loss: 2.1100e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.0772 - accuracy: 0.9786\n",
      "Epoch 74: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0903 - accuracy: 0.9715 - val_loss: 1.6119e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.0911 - accuracy: 0.9729\n",
      "Epoch 75: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0862 - accuracy: 0.9729 - val_loss: 1.7338e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.0864 - accuracy: 0.9738\n",
      "Epoch 76: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0793 - accuracy: 0.9777 - val_loss: 2.0942e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.1250 - accuracy: 0.9766\n",
      "Epoch 77: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1034 - accuracy: 0.9767 - val_loss: 2.3901e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.0869 - accuracy: 0.9794\n",
      "Epoch 78: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0850 - accuracy: 0.9777 - val_loss: 2.9133e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.0739 - accuracy: 0.9799\n",
      "Epoch 79: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0801 - accuracy: 0.9784 - val_loss: 2.8992e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "14/23 [=================>............] - ETA: 0s - loss: 0.0838 - accuracy: 0.9788\n",
      "Epoch 80: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0875 - accuracy: 0.9794 - val_loss: 3.8406e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0929 - accuracy: 0.9714\n",
      "Epoch 81: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0915 - accuracy: 0.9715 - val_loss: 1.4719e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "13/23 [===============>..............] - ETA: 0s - loss: 0.0987 - accuracy: 0.9730\n",
      "Epoch 82: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0930 - accuracy: 0.9750 - val_loss: 1.0948e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "13/23 [===============>..............] - ETA: 0s - loss: 0.0805 - accuracy: 0.9748\n",
      "Epoch 83: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0763 - accuracy: 0.9763 - val_loss: 3.8706e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.0807 - accuracy: 0.9828\n",
      "Epoch 84: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0836 - accuracy: 0.9805 - val_loss: 5.2641e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9842\n",
      "Epoch 85: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0707 - accuracy: 0.9842 - val_loss: 4.7105e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.0896 - accuracy: 0.9776\n",
      "Epoch 86: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1027 - accuracy: 0.9743 - val_loss: 1.5073e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "15/23 [==================>...........] - ETA: 0s - loss: 0.0849 - accuracy: 0.9745\n",
      "Epoch 87: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1107 - accuracy: 0.9753 - val_loss: 1.0961e-04 - val_accuracy: 1.0000\n",
      "Epoch 87: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f2a5cb70c70>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0961e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n",
      "[1.0000000e+00 2.2068558e-15 1.7999995e-10 4.2283857e-26 3.7312906e-21]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       197\n",
      "           1       1.00      1.00      1.00       217\n",
      "           2       1.00      1.00      1.00       136\n",
      "           3       1.00      1.00      1.00       202\n",
      "           4       1.00      1.00      1.00       221\n",
      "\n",
      "    accuracy                           1.00       973\n",
      "   macro avg       1.00      1.00      1.00       973\n",
      "weighted avg       1.00      1.00      1.00       973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/myenv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwagqripj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwagqripj/assets\n",
      "2024-01-09 16:19:52.584758: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-09 16:19:52.584786: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-09 16:19:52.584989: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpwagqripj\n",
      "2024-01-09 16:19:52.586754: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-09 16:19:52.586802: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpwagqripj\n",
      "2024-01-09 16:19:52.590749: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-09 16:19:52.645882: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpwagqripj\n",
      "2024-01-09 16:19:52.663204: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 78216 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 8, Total Ops 19, % non-converted = 42.11 %\n",
      " * 8 ARITH ops\n",
      "\n",
      "- arith.constant:    8 occurrences  (f32: 8)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (uq_8: 2)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17808"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 484 µs, sys: 36 µs, total: 520 µs\n",
      "Wall time: 412 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 2.9260298e-15 3.7172748e-10 7.6268256e-26 6.1521158e-21]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
