{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 17:11:45.349303: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-10 17:11:45.349509: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-10 17:11:45.352502: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-10 17:11:45.363953: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-10 17:11:46.615608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/two_hands_keypoint_classifier/two_hands_keypoint.csv'\n",
    "model_save_path = 'model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2 * 2, )),\n",
    "    tf.keras.layers.Dense(80, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 80)                6800      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 80)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                3240      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 40)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11136 (43.50 KB)\n",
      "Trainable params: 11136 (43.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/28 [================>.............] - ETA: 0s - loss: 1.6588 - accuracy: 0.2783 \n",
      "Epoch 1: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 2s 16ms/step - loss: 1.5575 - accuracy: 0.3184 - val_loss: 1.1465 - val_accuracy: 0.4286\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1081 - accuracy: 0.5126"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/myenv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1081 - accuracy: 0.5126 - val_loss: 0.6968 - val_accuracy: 0.8333\n",
      "Epoch 3/1000\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 0.7575 - accuracy: 0.6650\n",
      "Epoch 3: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.7534 - accuracy: 0.6657 - val_loss: 0.3479 - val_accuracy: 0.9881\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5350 - accuracy: 0.7993\n",
      "Epoch 4: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.5350 - accuracy: 0.7993 - val_loss: 0.2282 - val_accuracy: 0.9770\n",
      "Epoch 5/1000\n",
      "14/28 [==============>...............] - ETA: 0s - loss: 0.4421 - accuracy: 0.8438\n",
      "Epoch 5: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.8577 - val_loss: 0.1448 - val_accuracy: 0.9770\n",
      "Epoch 6/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.3491 - accuracy: 0.8726\n",
      "Epoch 6: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.3253 - accuracy: 0.8821 - val_loss: 0.0970 - val_accuracy: 0.9719\n",
      "Epoch 7/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.2666 - accuracy: 0.9058\n",
      "Epoch 7: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2750 - accuracy: 0.9042 - val_loss: 0.0695 - val_accuracy: 0.9762\n",
      "Epoch 8/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.2425 - accuracy: 0.9136\n",
      "Epoch 8: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2330 - accuracy: 0.9155 - val_loss: 0.0600 - val_accuracy: 0.9787\n",
      "Epoch 9/1000\n",
      "17/28 [=================>............] - ETA: 0s - loss: 0.2079 - accuracy: 0.9274\n",
      "Epoch 9: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2055 - accuracy: 0.9271 - val_loss: 0.0430 - val_accuracy: 0.9881\n",
      "Epoch 10/1000\n",
      "17/28 [=================>............] - ETA: 0s - loss: 0.1742 - accuracy: 0.9370\n",
      "Epoch 10: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1729 - accuracy: 0.9365 - val_loss: 0.0407 - val_accuracy: 0.9889\n",
      "Epoch 11/1000\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 0.1616 - accuracy: 0.9426\n",
      "Epoch 11: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.1662 - accuracy: 0.9410 - val_loss: 0.0327 - val_accuracy: 0.9906\n",
      "Epoch 12/1000\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 0.1423 - accuracy: 0.9486\n",
      "Epoch 12: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.1414 - accuracy: 0.9498 - val_loss: 0.0271 - val_accuracy: 0.9949\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9578\n",
      "Epoch 13: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1269 - accuracy: 0.9578 - val_loss: 0.0240 - val_accuracy: 0.9949\n",
      "Epoch 14/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.1203 - accuracy: 0.9600\n",
      "Epoch 14: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1280 - accuracy: 0.9566 - val_loss: 0.0200 - val_accuracy: 0.9957\n",
      "Epoch 15/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.1215 - accuracy: 0.9552\n",
      "Epoch 15: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.1224 - accuracy: 0.9541 - val_loss: 0.0207 - val_accuracy: 0.9949\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9623\n",
      "Epoch 16: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1057 - accuracy: 0.9623 - val_loss: 0.0228 - val_accuracy: 0.9932\n",
      "Epoch 17/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0896 - accuracy: 0.9741\n",
      "Epoch 17: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0978 - accuracy: 0.9688 - val_loss: 0.0173 - val_accuracy: 0.9957\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9629\n",
      "Epoch 18: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1034 - accuracy: 0.9629 - val_loss: 0.0168 - val_accuracy: 0.9957\n",
      "Epoch 19/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0834 - accuracy: 0.9703\n",
      "Epoch 19: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0912 - accuracy: 0.9680 - val_loss: 0.0163 - val_accuracy: 0.9957\n",
      "Epoch 20/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0836 - accuracy: 0.9702\n",
      "Epoch 20: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9714 - val_loss: 0.0162 - val_accuracy: 0.9957\n",
      "Epoch 21/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0905 - accuracy: 0.9712\n",
      "Epoch 21: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0847 - accuracy: 0.9750 - val_loss: 0.0132 - val_accuracy: 0.9966\n",
      "Epoch 22/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0901 - accuracy: 0.9667\n",
      "Epoch 22: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0848 - accuracy: 0.9694 - val_loss: 0.0101 - val_accuracy: 0.9974\n",
      "Epoch 23/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0851 - accuracy: 0.9745\n",
      "Epoch 23: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0766 - accuracy: 0.9762 - val_loss: 0.0115 - val_accuracy: 0.9966\n",
      "Epoch 24/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0797 - accuracy: 0.9719\n",
      "Epoch 24: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0707 - accuracy: 0.9765 - val_loss: 0.0113 - val_accuracy: 0.9966\n",
      "Epoch 25/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0659 - accuracy: 0.9819\n",
      "Epoch 25: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0683 - accuracy: 0.9816 - val_loss: 0.0112 - val_accuracy: 0.9974\n",
      "Epoch 26/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0564 - accuracy: 0.9814\n",
      "Epoch 26: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0596 - accuracy: 0.9804 - val_loss: 0.0120 - val_accuracy: 0.9966\n",
      "Epoch 27/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0518 - accuracy: 0.9844\n",
      "Epoch 27: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 0.9819 - val_loss: 0.0119 - val_accuracy: 0.9966\n",
      "Epoch 28/1000\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.0609 - accuracy: 0.9780\n",
      "Epoch 28: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.0607 - accuracy: 0.9779 - val_loss: 0.0126 - val_accuracy: 0.9966\n",
      "Epoch 29/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0659 - accuracy: 0.9766\n",
      "Epoch 29: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0618 - accuracy: 0.9785 - val_loss: 0.0087 - val_accuracy: 0.9983\n",
      "Epoch 30/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0498 - accuracy: 0.9839\n",
      "Epoch 30: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0550 - accuracy: 0.9813 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 31/1000\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.0584 - accuracy: 0.9792\n",
      "Epoch 31: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0589 - accuracy: 0.9787 - val_loss: 0.0076 - val_accuracy: 0.9983\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9827\n",
      "Epoch 32: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0528 - accuracy: 0.9827 - val_loss: 0.0089 - val_accuracy: 0.9983\n",
      "Epoch 33/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0514 - accuracy: 0.9849\n",
      "Epoch 33: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0539 - accuracy: 0.9841 - val_loss: 0.0101 - val_accuracy: 0.9974\n",
      "Epoch 34/1000\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.0494 - accuracy: 0.9847\n",
      "Epoch 34: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0527 - accuracy: 0.9827 - val_loss: 0.0086 - val_accuracy: 0.9983\n",
      "Epoch 35/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0523 - accuracy: 0.9839\n",
      "Epoch 35: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0514 - accuracy: 0.9841 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 36/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0415 - accuracy: 0.9844\n",
      "Epoch 36: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0434 - accuracy: 0.9853 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 37/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0470 - accuracy: 0.9870\n",
      "Epoch 37: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0488 - accuracy: 0.9864 - val_loss: 0.0090 - val_accuracy: 0.9974\n",
      "Epoch 38/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9850\n",
      "Epoch 38: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.0435 - accuracy: 0.9850 - val_loss: 0.0093 - val_accuracy: 0.9974\n",
      "Epoch 39/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0517 - accuracy: 0.9834\n",
      "Epoch 39: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0494 - accuracy: 0.9838 - val_loss: 0.0070 - val_accuracy: 0.9983\n",
      "Epoch 40/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0486 - accuracy: 0.9833\n",
      "Epoch 40: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
      "Epoch 41/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0445 - accuracy: 0.9858\n",
      "Epoch 41: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0449 - accuracy: 0.9850 - val_loss: 0.0075 - val_accuracy: 0.9991\n",
      "Epoch 42/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9853\n",
      "Epoch 42: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9853 - val_loss: 0.0075 - val_accuracy: 0.9991\n",
      "Epoch 43/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0527 - accuracy: 0.9814\n",
      "Epoch 43: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0511 - accuracy: 0.9813 - val_loss: 0.0090 - val_accuracy: 0.9983\n",
      "Epoch 44/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9844\n",
      "Epoch 44: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0479 - accuracy: 0.9844 - val_loss: 0.0236 - val_accuracy: 0.9932\n",
      "Epoch 45/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9836\n",
      "Epoch 45: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0503 - accuracy: 0.9836 - val_loss: 0.0094 - val_accuracy: 0.9983\n",
      "Epoch 46/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0380 - accuracy: 0.9896\n",
      "Epoch 46: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9864 - val_loss: 0.0055 - val_accuracy: 0.9991\n",
      "Epoch 47/1000\n",
      "17/28 [=================>............] - ETA: 0s - loss: 0.0345 - accuracy: 0.9894\n",
      "Epoch 47: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9884 - val_loss: 0.0064 - val_accuracy: 0.9991\n",
      "Epoch 48/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0482 - accuracy: 0.9829\n",
      "Epoch 48: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0463 - accuracy: 0.9841 - val_loss: 0.0065 - val_accuracy: 0.9991\n",
      "Epoch 49/1000\n",
      "18/28 [==================>...........] - ETA: 0s - loss: 0.0418 - accuracy: 0.9874\n",
      "Epoch 49: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0385 - accuracy: 0.9875 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 50/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0317 - accuracy: 0.9893\n",
      "Epoch 50: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9881 - val_loss: 0.0059 - val_accuracy: 0.9991\n",
      "Epoch 51/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0408 - accuracy: 0.9863\n",
      "Epoch 51: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9841 - val_loss: 0.0070 - val_accuracy: 0.9991\n",
      "Epoch 52/1000\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 0.0317 - accuracy: 0.9895\n",
      "Epoch 52: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.0074 - val_accuracy: 0.9991\n",
      "Epoch 53/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0287 - accuracy: 0.9902\n",
      "Epoch 53: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 0.0082 - val_accuracy: 0.9991\n",
      "Epoch 54/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0312 - accuracy: 0.9911\n",
      "Epoch 54: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 0.9898 - val_loss: 0.0089 - val_accuracy: 0.9983\n",
      "Epoch 55/1000\n",
      "16/28 [================>.............] - ETA: 0s - loss: 0.0323 - accuracy: 0.9917\n",
      "Epoch 55: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9901 - val_loss: 0.0076 - val_accuracy: 0.9991\n",
      "Epoch 56/1000\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 0.0334 - accuracy: 0.9889\n",
      "Epoch 56: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.0078 - val_accuracy: 0.9991\n",
      "Epoch 57/1000\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 0.0338 - accuracy: 0.9896\n",
      "Epoch 57: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.0073 - val_accuracy: 0.9991\n",
      "Epoch 58/1000\n",
      "23/28 [=======================>......] - ETA: 0s - loss: 0.0256 - accuracy: 0.9925\n",
      "Epoch 58: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9929 - val_loss: 0.0070 - val_accuracy: 0.9991\n",
      "Epoch 59/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0416 - accuracy: 0.9844\n",
      "Epoch 59: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.9867 - val_loss: 0.0080 - val_accuracy: 0.9991\n",
      "Epoch 60/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0253 - accuracy: 0.9906\n",
      "Epoch 60: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9901 - val_loss: 0.0081 - val_accuracy: 0.9991\n",
      "Epoch 61/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0248 - accuracy: 0.9943\n",
      "Epoch 61: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9938 - val_loss: 0.0073 - val_accuracy: 0.9991\n",
      "Epoch 62/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9901\n",
      "Epoch 62: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 0.9901 - val_loss: 0.0076 - val_accuracy: 0.9991\n",
      "Epoch 63/1000\n",
      "23/28 [=======================>......] - ETA: 0s - loss: 0.0266 - accuracy: 0.9915\n",
      "Epoch 63: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0272 - accuracy: 0.9904 - val_loss: 0.0087 - val_accuracy: 0.9991\n",
      "Epoch 64/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9892\n",
      "Epoch 64: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0407 - accuracy: 0.9892 - val_loss: 0.0092 - val_accuracy: 0.9991\n",
      "Epoch 65/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0336 - accuracy: 0.9891\n",
      "Epoch 65: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.9892 - val_loss: 0.0081 - val_accuracy: 0.9991\n",
      "Epoch 66/1000\n",
      "15/28 [===============>..............] - ETA: 0s - loss: 0.0325 - accuracy: 0.9901\n",
      "Epoch 66: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.0071 - val_accuracy: 0.9991\n",
      "Epoch 66: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f94101f27d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.8670e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9991\n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 123ms/step\n",
      "[3.1548695e-18 4.7190152e-10 7.6304950e-14 8.8033448e-32 7.5937376e-24\n",
      " 1.0000000e+00]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       298\n",
      "           1       1.00      1.00      1.00       197\n",
      "           2       1.00      0.99      1.00       164\n",
      "           3       1.00      1.00      1.00       205\n",
      "           4       1.00      1.00      1.00       130\n",
      "           5       1.00      1.00      1.00       182\n",
      "\n",
      "    accuracy                           1.00      1176\n",
      "   macro avg       1.00      1.00      1.00      1176\n",
      "weighted avg       1.00      1.00      1.00      1176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/myenv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkhxzg4f4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkhxzg4f4/assets\n",
      "2024-01-10 17:12:09.230473: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-10 17:12:09.230569: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-10 17:12:09.231082: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpkhxzg4f4\n",
      "2024-01-10 17:12:09.233047: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-10 17:12:09.233073: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpkhxzg4f4\n",
      "2024-01-10 17:12:09.236712: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-01-10 17:12:09.237964: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-10 17:12:09.295291: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpkhxzg4f4\n",
      "2024-01-10 17:12:09.317415: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 86334 microseconds.\n",
      "2024-01-10 17:12:09.337964: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 8, Total Ops 19, % non-converted = 42.11 %\n",
      " * 8 ARITH ops\n",
      "\n",
      "- arith.constant:    8 occurrences  (f32: 8)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (uq_8: 2)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17816"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.92 ms, sys: 0 ns, total: 1.92 ms\n",
      "Wall time: 1.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.5262846e-18 4.9809373e-10 8.3476764e-14 1.0830529e-31 8.8991375e-24\n",
      " 1.0000000e+00]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
