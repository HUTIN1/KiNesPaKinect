{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 12:02:21.645487: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-10 12:02:21.645521: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-10 12:02:21.646782: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-10 12:02:21.653073: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-10 12:02:22.701559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/two_hands_keypoint_classifier/two_hands_keypoint.csv'\n",
    "model_save_path = 'model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2 * 2, )),\n",
    "    tf.keras.layers.Dense(80, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 80)                6800      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 80)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                3240      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 40)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11125 (43.46 KB)\n",
      "Trainable params: 11125 (43.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/24 [=====================>........] - ETA: 0s - loss: 1.4639 - accuracy: 0.3346 \n",
      "Epoch 1: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 2s 22ms/step - loss: 1.4255 - accuracy: 0.3470 - val_loss: 1.2207 - val_accuracy: 0.4550\n",
      "Epoch 2/1000\n",
      "15/24 [=================>............] - ETA: 0s - loss: 1.1629 - accuracy: 0.4771\n",
      "Epoch 2: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/myenv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 9ms/step - loss: 1.1089 - accuracy: 0.5053 - val_loss: 0.8180 - val_accuracy: 0.6970\n",
      "Epoch 3/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.8426 - accuracy: 0.6466\n",
      "Epoch 3: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7966 - accuracy: 0.6673 - val_loss: 0.5278 - val_accuracy: 0.8260\n",
      "Epoch 4/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.6238 - accuracy: 0.7427\n",
      "Epoch 4: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5950 - accuracy: 0.7530 - val_loss: 0.3623 - val_accuracy: 0.8650\n",
      "Epoch 5/1000\n",
      "15/24 [=================>............] - ETA: 0s - loss: 0.4733 - accuracy: 0.8016\n",
      "Epoch 5: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4708 - accuracy: 0.7990 - val_loss: 0.2834 - val_accuracy: 0.8570\n",
      "Epoch 6/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.3851 - accuracy: 0.8347\n",
      "Epoch 6: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3841 - accuracy: 0.8297 - val_loss: 0.2366 - val_accuracy: 0.8580\n",
      "Epoch 7/1000\n",
      "16/24 [===================>..........] - ETA: 0s - loss: 0.3398 - accuracy: 0.8433\n",
      "Epoch 7: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3390 - accuracy: 0.8397 - val_loss: 0.2080 - val_accuracy: 0.8690\n",
      "Epoch 8/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.3184 - accuracy: 0.8532\n",
      "Epoch 8: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3027 - accuracy: 0.8623 - val_loss: 0.1823 - val_accuracy: 0.8700\n",
      "Epoch 9/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.3051 - accuracy: 0.8576\n",
      "Epoch 9: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2785 - accuracy: 0.8723 - val_loss: 0.1610 - val_accuracy: 0.9430\n",
      "Epoch 10/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.2412 - accuracy: 0.9057\n",
      "Epoch 10: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.2369 - accuracy: 0.9130 - val_loss: 0.1397 - val_accuracy: 0.9920\n",
      "Epoch 11/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.2236 - accuracy: 0.9498\n",
      "Epoch 11: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2135 - accuracy: 0.9540 - val_loss: 0.1181 - val_accuracy: 0.9960\n",
      "Epoch 12/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.2117 - accuracy: 0.9513\n",
      "Epoch 12: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1975 - accuracy: 0.9553 - val_loss: 0.0933 - val_accuracy: 0.9940\n",
      "Epoch 13/1000\n",
      "15/24 [=================>............] - ETA: 0s - loss: 0.1585 - accuracy: 0.9573\n",
      "Epoch 13: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1588 - accuracy: 0.9560 - val_loss: 0.0678 - val_accuracy: 0.9930\n",
      "Epoch 14/1000\n",
      "15/24 [=================>............] - ETA: 0s - loss: 0.1398 - accuracy: 0.9609\n",
      "Epoch 14: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1382 - accuracy: 0.9607 - val_loss: 0.0555 - val_accuracy: 0.9920\n",
      "Epoch 15/1000\n",
      "15/24 [=================>............] - ETA: 0s - loss: 0.1149 - accuracy: 0.9656\n",
      "Epoch 15: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1175 - accuracy: 0.9633 - val_loss: 0.0341 - val_accuracy: 0.9950\n",
      "Epoch 16/1000\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9630\n",
      "Epoch 16: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1121 - accuracy: 0.9630 - val_loss: 0.0334 - val_accuracy: 0.9940\n",
      "Epoch 17/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.1049 - accuracy: 0.9706\n",
      "Epoch 17: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0921 - accuracy: 0.9713 - val_loss: 0.0299 - val_accuracy: 0.9940\n",
      "Epoch 18/1000\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.0865 - accuracy: 0.9745\n",
      "Epoch 18: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0861 - accuracy: 0.9737 - val_loss: 0.0292 - val_accuracy: 0.9940\n",
      "Epoch 19/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0923 - accuracy: 0.9694\n",
      "Epoch 19: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.9733 - val_loss: 0.0214 - val_accuracy: 0.9960\n",
      "Epoch 20/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0739 - accuracy: 0.9736\n",
      "Epoch 20: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0792 - accuracy: 0.9730 - val_loss: 0.0205 - val_accuracy: 0.9960\n",
      "Epoch 21/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0833 - accuracy: 0.9736\n",
      "Epoch 21: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0852 - accuracy: 0.9730 - val_loss: 0.0263 - val_accuracy: 0.9940\n",
      "Epoch 22/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.0738 - accuracy: 0.9799\n",
      "Epoch 22: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0732 - accuracy: 0.9790 - val_loss: 0.0222 - val_accuracy: 0.9950\n",
      "Epoch 23/1000\n",
      "12/24 [==============>...............] - ETA: 0s - loss: 0.0623 - accuracy: 0.9831\n",
      "Epoch 23: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0646 - accuracy: 0.9817 - val_loss: 0.0201 - val_accuracy: 0.9950\n",
      "Epoch 24/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0570 - accuracy: 0.9814\n",
      "Epoch 24: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0615 - accuracy: 0.9803 - val_loss: 0.0215 - val_accuracy: 0.9960\n",
      "Epoch 25/1000\n",
      "12/24 [==============>...............] - ETA: 0s - loss: 0.0511 - accuracy: 0.9876\n",
      "Epoch 25: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0562 - accuracy: 0.9847 - val_loss: 0.0195 - val_accuracy: 0.9950\n",
      "Epoch 26/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0602 - accuracy: 0.9826\n",
      "Epoch 26: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0582 - accuracy: 0.9820 - val_loss: 0.0159 - val_accuracy: 0.9960\n",
      "Epoch 27/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0563 - accuracy: 0.9802\n",
      "Epoch 27: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9830 - val_loss: 0.0153 - val_accuracy: 0.9970\n",
      "Epoch 28/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.0611 - accuracy: 0.9844\n",
      "Epoch 28: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0581 - accuracy: 0.9833 - val_loss: 0.0161 - val_accuracy: 0.9970\n",
      "Epoch 29/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0515 - accuracy: 0.9838\n",
      "Epoch 29: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0528 - accuracy: 0.9833 - val_loss: 0.0151 - val_accuracy: 0.9970\n",
      "Epoch 30/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0508 - accuracy: 0.9886\n",
      "Epoch 30: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0498 - accuracy: 0.9880 - val_loss: 0.0185 - val_accuracy: 0.9960\n",
      "Epoch 31/1000\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0510 - accuracy: 0.9851\n",
      "Epoch 31: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0506 - accuracy: 0.9853 - val_loss: 0.0194 - val_accuracy: 0.9960\n",
      "Epoch 32/1000\n",
      "15/24 [=================>............] - ETA: 0s - loss: 0.0461 - accuracy: 0.9911\n",
      "Epoch 32: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0502 - accuracy: 0.9887 - val_loss: 0.0225 - val_accuracy: 0.9960\n",
      "Epoch 33/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.0458 - accuracy: 0.9866\n",
      "Epoch 33: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0448 - accuracy: 0.9880 - val_loss: 0.0160 - val_accuracy: 0.9980\n",
      "Epoch 34/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.0558 - accuracy: 0.9838\n",
      "Epoch 34: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0530 - accuracy: 0.9850 - val_loss: 0.0182 - val_accuracy: 0.9970\n",
      "Epoch 35/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.0407 - accuracy: 0.9877\n",
      "Epoch 35: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9880 - val_loss: 0.0197 - val_accuracy: 0.9970\n",
      "Epoch 36/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0371 - accuracy: 0.9898\n",
      "Epoch 36: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 0.0225 - val_accuracy: 0.9960\n",
      "Epoch 37/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0408 - accuracy: 0.9880\n",
      "Epoch 37: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0435 - accuracy: 0.9873 - val_loss: 0.0191 - val_accuracy: 0.9970\n",
      "Epoch 38/1000\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 0.0492 - accuracy: 0.9863\n",
      "Epoch 38: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0483 - accuracy: 0.9870 - val_loss: 0.0233 - val_accuracy: 0.9960\n",
      "Epoch 39/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0387 - accuracy: 0.9892\n",
      "Epoch 39: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0479 - accuracy: 0.9857 - val_loss: 0.0187 - val_accuracy: 0.9980\n",
      "Epoch 40/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0464 - accuracy: 0.9874\n",
      "Epoch 40: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0466 - accuracy: 0.9863 - val_loss: 0.0211 - val_accuracy: 0.9970\n",
      "Epoch 41/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.0402 - accuracy: 0.9888\n",
      "Epoch 41: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0408 - accuracy: 0.9887 - val_loss: 0.0204 - val_accuracy: 0.9980\n",
      "Epoch 42/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0419 - accuracy: 0.9868\n",
      "Epoch 42: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0440 - accuracy: 0.9863 - val_loss: 0.0214 - val_accuracy: 0.9970\n",
      "Epoch 43/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.0479 - accuracy: 0.9860\n",
      "Epoch 43: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 0.9867 - val_loss: 0.0230 - val_accuracy: 0.9970\n",
      "Epoch 44/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0405 - accuracy: 0.9904\n",
      "Epoch 44: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0374 - accuracy: 0.9917 - val_loss: 0.0231 - val_accuracy: 0.9970\n",
      "Epoch 45/1000\n",
      "15/24 [=================>............] - ETA: 0s - loss: 0.0371 - accuracy: 0.9911\n",
      "Epoch 45: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0336 - accuracy: 0.9903 - val_loss: 0.0311 - val_accuracy: 0.9960\n",
      "Epoch 46/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.0471 - accuracy: 0.9872\n",
      "Epoch 46: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0421 - accuracy: 0.9893 - val_loss: 0.0256 - val_accuracy: 0.9970\n",
      "Epoch 47/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.0341 - accuracy: 0.9916\n",
      "Epoch 47: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 0.9910 - val_loss: 0.0231 - val_accuracy: 0.9980\n",
      "Epoch 48/1000\n",
      "14/24 [================>.............] - ETA: 0s - loss: 0.0354 - accuracy: 0.9894\n",
      "Epoch 48: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0337 - accuracy: 0.9907 - val_loss: 0.0233 - val_accuracy: 0.9980\n",
      "Epoch 49/1000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0379 - accuracy: 0.9898\n",
      "Epoch 49: saving model to model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9913 - val_loss: 0.0271 - val_accuracy: 0.9970\n",
      "Epoch 49: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f70087127d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0271 - accuracy: 0.9970\n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 107ms/step\n",
      "[5.1718654e-08 9.9999750e-01 2.4847989e-06 9.0764243e-11 7.2476491e-09]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAH5CAYAAACWFaT0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6uElEQVR4nO3deXRU5f3H8c9kJQSSGLKBgKJUAdlkaUhFVKACokhxQ1HBUqyYUCFFJf4UFJegoCyKolZZWqlLKy6oWArKIgEhyI4LuABCEgKSkECGJHN/f1CnHS9LJuZm5onvl+eeQ+7cufnOc+bIl8/z3HtdlmVZAgAAMFhIoAsAAAD4uWhoAACA8WhoAACA8WhoAACA8WhoAACA8WhoAACA8WhoAACA8WhoAACA8cICXcCPygu/DnQJdVZUk4sDXQKAIOEKdAF1WPmx72vvdzn4d2Z4wjmOndtJJDQAAMB4QZPQAACAKvJUBrqCoENCAwAAjEdCAwCAaSxPoCsIOiQ0AADAeCQ0AACYxkNC81M0NAAAGMZiysmGKScAAGA8EhoAAEzDlJMNCQ0AADAeCQ0AAKZhDY0NCQ0AADAeCQ0AAKbh0Qc2JDQAAMB4JDQAAJiGNTQ2JDQAAMB4JDQAAJiG+9DY0NAAAGAYHn1gx5QTAAAwHgkNAACmYcrJhoQGAAAYj4QGAADTsIbGhoQGAAAYj4QGAADT8OgDGxIaAABgPBIaAABMwxoaGxoaAABMw2XbNkw5AQAA45HQAABgGqacbEhoAACA8UhoAAAwDWtobEhoAACA8UhoAAAwjGVxY72fIqEBAADGI6EBAMA0XOVkQ0MDAIBpWBRsw5QTAAAwHgkNAACmYcrJhoQGAAAYj4QGAADTeLhs+6dIaCS9OO813TD8T/p170Hq0X+w/jRuor75bo/PMbv27NWfsibq4v43KPW3g/TnBx5T4cEffI7JuOdB9R50qzpdNkCXDrhJ4yZOVsH+A7X5UYw18o6h2vHlapUU79Sqle+qa5eOgS6pzmBsncPY1rx77slQzqr3dPDAF/p+z0b94x8v6bzzzg10WTAADY2kdRs268ZBV2n+C1P1wrTHVF5RodvH/J+OHC2TJB05Wqbbx/yfXHLppRmT9NdZT6q8vEIZ9zwoz/+sNP91pw56cmKWFv79RU199H7t/n6fxtz/aKA+ljGuu26ApkyeoIcfeUpdU/tq46Ztev+9V5SY2CjQpRmPsXUOY+uMHhd303PPzVX3i69SvytuVHhYuN5/b77q148KdGnBxfI4txnKZVmWFegiJKm88OtAl+B18IdD6nHljZoz8wl16dhOn6zJ1cix47Vq0etqEB0tSTpcUqrf9L1OL0x9VGldLzzheT5asVp/ypqo9R+/o/CwwM3uRTW5OGC/uypWrXxXa9dt1F2j75ckuVwuffv1Ws18draemDwzwNWZjbF1jqlj6wp0AX5KSIjXvr2bdVnPQVq5ck2gyzml8mPf19rvKvv0DcfOXe/X1zl2bieR0JxASekRSVJsTENJUnl5uVwuKSI83HtMZES4QkJcWr9p6wnPUVR8WAv/9ZE6tmsd0GYm2IWHh6tTp/ZasnSFd59lWVqydKW6descwMrMx9g6h7GtPbGxMZKkH344FNhCgo3H49xmKL//pi0sLNTLL7+snJwc5eXlSZJSUlL0m9/8RsOGDVNiYuJpz+F2u+V2u332hbjdioyM9LecGufxeDRp+vO6sH0b/eqcsyVJ7S9opah69fTUsy/rrjuGybKkac+9rMpKjwoPHPR5/1PPvqS///NdHS1zq8MFrTRz8kMB+BTmSEiIV1hYmAryC332FxTsV6vzmTf/ORhb5zC2tcPlcunJKQ/pk08+1datXwS6nOBi8NSQU/xKaNauXavzzjtPM2bMUGxsrHr06KEePXooNjZWM2bMUKtWrbRu3brTnic7O1uxsbE+2+PTZ1X7Q9SkR56cqR1ff6vJD43z7os/I05PPnyfPv5kjX7de5DS+lyj4pJStTm/pVwu3wD3tpuu1Ruzn9ELUx9VSGiIsh6eoiCZ1QMAozw94zFdcMH5GnLznYEuBQbwK6EZNWqUrrvuOs2aNcv2F7llWbrjjjs0atQo5eTknPI8WVlZyszM9NkXcrj25h5P5tEnn9WyVZ9q7szJSknyTZouSu2sRW/M1g+HihQaGqqYhg10yVU3qW+vxj7HnREXqzPiYnV286Y65+xm6v27W7Vx6+fq2LZ1bX4UYxQWHlRFRYWSkhN89iclJSovf3+AqqobGFvnMLbOmz7tEV1xRW/17DVI33+/L9DlBB+Dp4ac4ldCs3HjRo0ZM8bWzEjHo8ExY8Zow4YNpz1PZGSkYmJifLZATjdZlqVHn3xWS5av0sszJqlpk5STHntGXKxiGjbQmtwNOvjDIV3WvdvJz+s5nswcO1Ze4zXXFeXl5Vq/fpN6Xtbdu8/lcqnnZd21enVuACszH2PrHMbWWdOnPaKrr+6ry/tcr2+/3R3ocmAIvxKalJQUffrpp2rVqtUJX//000+VnJxcI4XVpkeenKn3F3+sGZPGK7p+lHddTIMG0ar3n0ZrwXv/0jlnNdMZcbHauPVzTZo2S7fe8Du1OKupJGnT1s+1ZfuX6tT+AsXENNDu7/fp6Rf/qmZnNlbHticeLxw3dfqLmv3SVOWu36S1az/Tn0aNUHR0lObMfS3QpRmPsXUOY+uMp2c8psGDB2rQNb/X4cMlSk4+npYXFR1WWVlZgKsLIiQ0Nn41NGPHjtXtt9+u3Nxc9erVy9u85Ofna8mSJXrxxRc1ZcoURwp10msL3pMk3ZZxr8/+R+7L1MD+v5Ukfbtrj6bNmqOi4sM6s3Gybh86WLfe8DvvsfXqRerfy1Zp5kt/09GyMiU2itdFqZ31x4ezFBERUXsfxkBvvPGOEhPi9eD4sUpJSdTGjVvV/8qbVVBQePo345QYW+cwts64446hkqSlS/7ps3/48DGa99fXA1ESDOH3fWhee+01TZ06Vbm5uaqsPH7r5dDQUHXu3FmZmZm6/vrrq1VIMN2Hpq4J9vvQAKg9pt2HxiS1eR+ao8vnOHbuqB7DHDu3k/y+bPuGG27QDTfcoPLychUWHv+XSEJCgsL/5x4tAAAAtanad3wLDw9X48aNT38gAACoWayhseEWtgAAmIYb69nw6AMAAGA8EhoAAEzDlJMNCQ0AADAeCQ0AAKZhDY0NCQ0AADAeCQ0AAKZhDY0NCQ0AADAeCQ0AAKZhDY0NDQ0AAKZhysmGKScAAFAt2dnZ6tq1qxo2bKikpCQNHDhQX3zxhc8xl156qVwul892xx13+Byza9cu9e/fX/Xr11dSUpLuvvtuVVRU+FULCQ0AAKYJkoRm2bJlSk9PV9euXVVRUaH77rtPl19+ubZt26bo6GjvcSNGjNDEiRO9P9evX9/758rKSvXv318pKSlatWqV9u3bp1tvvVXh4eF67LHHqlwLDQ0AAKiWRYsW+fw8Z84cJSUlKTc3Vz169PDur1+/vlJSUk54jn/961/atm2b/v3vfys5OVkdO3bUww8/rHvvvVcPPvigIiIiqlQLU04AAJjG8ji2ud1uFRcX+2xut7tKZRUVFUmS4uPjffa/8sorSkhIUNu2bZWVlaUjR454X8vJyVG7du2UnJzs3denTx8VFxdr69atVR4SGhoAAOCVnZ2t2NhYny07O/u07/N4PBo9erQuuugitW3b1rv/pptu0t/+9jd99NFHysrK0l//+lfdfPPN3tfz8vJ8mhlJ3p/z8vKqXDdTTgAAmMbBNTRZWVnKzMz02RcZGXna96Wnp2vLli1auXKlz/7bb7/d++d27dqpcePG6tWrl3bu3Klzzz23ZooWCQ0AAPgfkZGRiomJ8dlO19BkZGRo4cKF+uijj9S0adNTHpuamipJ2rFjhyQpJSVF+fn5Psf8+PPJ1t2cCA0NAACmcXANjV9lWJYyMjK0YMECLV26VC1atDjtezZs2CBJaty4sSQpLS1NmzdvVkFBgfeYxYsXKyYmRm3atKlyLUw5AQBgmiC5bDs9PV3z58/X22+/rYYNG3rXvMTGxioqKko7d+7U/PnzdcUVV6hRo0batGmTxowZox49eqh9+/aSpMsvv1xt2rTRLbfcoieeeEJ5eXm6//77lZ6eXqWprh+5LMuyHPmUfiov/DrQJdRZUU0uDnQJAIKEK9AF1GHlx76vtd91dMEkx84d9btxVT7W5TrxN2r27NkaNmyYdu/erZtvvllbtmxRaWmpmjVrpt/97ne6//77FRMT4z3+u+++08iRI/Xxxx8rOjpaQ4cO1aRJkxQWVvXchYQGAADTBMmznE6XiTRr1kzLli077XnOOussvf/++z+rFtbQAAAA45HQAABgmiBZQxNMSGgAAIDxSGgAADANCY0NCQ0AADAeCQ0AAKYJjjuuBBUaGgAATMOUkw1TTgAAwHgkNAAAmIaExoaEBgAAGI+EBgAA0wTJow+CCQkNAAAwHgkNAACmYQ2NDQkNAAAwHgkNAACm4cZ6NiQ0AADAeCQ0AACYhjU0NjQ0AACYhobGJmgamqgmFwe6hDrrUEbnQJdQJ8U9kxvoEgC/sfICdVXQNDQAAKCKuLGeDYuCAQCA8UhoAAAwjOVh8vCnSGgAAIDxSGgAADANVznZkNAAAADjkdAAAGAarnKyoaEBAMA0LAq2YcoJAAAYj4QGAADTsCjYhoQGAAAYj4QGAADTkNDYkNAAAADjkdAAAGAai6ucfoqEBgAAGI+EBgAA07CGxoaGBgAA03BjPRumnAAAgPFIaAAAMA3PcrIhoQEAAMYjoQEAwDSsobEhoQEAAMYjoQEAwDAWl23bkNAAAADjkdAAAGAa1tDY0NAAAGAaLtu2YcoJAAAYj4QGAADTMOVkQ0IDAACMR0IDAIBpuGzbhoQGAAAYj4QGAADTsIbGhoQGAAAYj4QGAADTcB8aGxoaAABMw5STDVNOAADAeCQ0AAAYhqdt25HQAAAA45HQAABgGtbQ2JDQAAAA49HQ+GnkHUO148vVKineqVUr31XXLh0DXVJQC+91raJGP6nox15V/Yfmqd5t98mVeKbvQWHhihj0R0U//DdFZ7+mesPGydUgznausK49FTV2hqIf/4fqPzRPEYP+WDsfwnB8Z53D2DqHsT0Nj+XcZigaGj9cd90ATZk8QQ8/8pS6pvbVxk3b9P57rygxsVGgSwtaoee2Vfkn7+no9LtV9vx4KTRUUX98SIqI9B4TefUfFHbBr1U29wkdnXmfXDHxqndbls95wi+5WhFX3KLypf/QkScyVDZrvCq/+Ky2P45x+M46h7F1DmOL6qCh8cOYu0boLy/N19x5r2v79q90Z/o4HTlyVLcNGxzo0oJW2QsPqmLtUnnyd8uz91uV/X26QuKTFNK05fED6tVXWGpvud9+SZU7NsmzZ6fKXp2u0BatFXLW+cePiYpWRL+b5Z4/VRXrl8s6kCfPvm9VufXTwH0wQ/CddQ5j6xzGtgosj3OboWhoqig8PFydOrXXkqUrvPssy9KSpSvVrVvnAFZmFldU9PE/HDksSQpt2lKusHBVfrnRe4xV8L08BwsU+p+GJuy8jpLLJVdsI9W/d6bqj39ZkbfeI1dcQm2XbxS+s85hbJ3D2FYRU042Nd7Q7N69W7///e9PeYzb7VZxcbHPZlnBPYgJCfEKCwtTQX6hz/6Cgv1KSU4MUFWGcbkUefUfVPn1Nnnydh3fFRMnq6JcKiv1OdQqOSRXzBnHj2mUIrlciuh1ndxv/UVlcx+Xq34DRf1xohTKhXonw3fWOYytcxhbVFeNNzQHDx7U3LlzT3lMdna2YmNjfTbLc7imS0GQiRx0h0IaN1fZXyf790ZXiFxh4XIveEGVX3wmz3dfqOyvU+RKbKzQlu2cKRYAgpjlsRzbTOX3P2/feeedU77+9ddfn/YcWVlZyszM9Nl3RqNW/pZSqwoLD6qiokJJyb7THElJicrL3x+gqswRMeiPCm3TRUdn3ier6IB3v1V8SK6wcKletE9K42oQJ6v4h/8cc1CS5Mnf/d8TlhbLKj0s1xn8i+1k+M46h7F1DmOL6vK7oRk4cKBcLtcpp4hcLtcpzxEZGanIyEiffad7T6CVl5dr/fpN6nlZd73zzoeSjtfc87Lueva52QGuLrhFDPqjwtp1O97MHMz3ea1yzw5ZFeUKPa+9KjflSJJciWcqJD5Jld99cfyYb7dLkkKSzlTlj81Q/QZyRTeUdbCg9j6IYfjOOoexdQ5jW0UGJylO8XvKqXHjxnrzzTfl8XhOuK1fv96JOoPC1Okv6g/Db9Itt1ynVq1aauYzkxQdHaU5c18LdGlBK/KaOxTe+RKV/W2K5D4qV8M4uRrGSeERxw8oO6KKNf9W5IDhCm3ZTiFNz1W9wX9S5Tfb5flPQ2Pt36uKzasVMXCEQs5upZCU5qp342h5Cr5X5Y7NgftwBuA76xzG1jmMLarD74Smc+fOys3N1dVXX33C10+X3pjsjTfeUWJCvB4cP1YpKYnauHGr+l95swoKCk//5l+o8IuukCTVT8/22V/292mqWLtUkuR++y+KsDyqN2ycFBquyi8+k/ufz/keP3+qIgf+QVF/GC9ZHlXu3KqyFx6UPJW18jlMxXfWOYytcxjbKgiSh1NmZ2frzTff1Oeff66oqCj95je/0eOPP67zzz/fe0xZWZn+/Oc/69VXX5Xb7VafPn307LPPKjk52XvMrl27NHLkSH300Udq0KCBhg4dquzsbIWFVb1NcVl+dh8rVqxQaWmp+vbte8LXS0tLtW7dOl1yySX+nFZhEWee/iBUy6EMLnV0QtwzuYEuAUAQqTj2fa39rsMZVzh27obPvF/lY/v27avBgwera9euqqio0H333actW7Zo27Ztio4+fpuOkSNH6r333tOcOXMUGxurjIwMhYSE6JNPPpEkVVZWqmPHjkpJSdHkyZO1b98+3XrrrRoxYoQee+yxKtfid0PjFBoa59DQOIOGBsD/qtWG5s5+jp274bMfVPu9+/fvV1JSkpYtW6YePXqoqKhIiYmJmj9/vq699lpJ0ueff67WrVsrJydH3bp10wcffKArr7xSe/fu9aY2s2bN0r333qv9+/crIiKiSr+bG+sBAGAaB2+sd6J7xbnd7iqVVVRUJEmKj4+XJOXm5qq8vFy9e/f2HtOqVSs1b95cOTnHLwTJyclRu3btfKag+vTpo+LiYm3durXKQ0JDAwAAvE50r7js7OzTvs/j8Wj06NG66KKL1LZtW0lSXl6eIiIiFBcX53NscnKy8vLyvMf8bzPz4+s/vlZV3GYVAADDOLla5ET3ivvprVZOJD09XVu2bNHKlSudKu2UaGgAAIDXie4VdzoZGRlauHChli9frqZNm3r3p6Sk6NixYzp06JBPSpOfn6+UlBTvMZ9+6vuw4fz8fO9rVcWUEwAApgmSh1NalqWMjAwtWLBAS5cuVYsWLXxe79y5s8LDw7VkyRLvvi+++EK7du1SWlqaJCktLU2bN29WQcF/b5S6ePFixcTEqE2bNlWuhYQGAABUS3p6uubPn6+3335bDRs29K55iY2NVVRUlGJjYzV8+HBlZmYqPj5eMTExGjVqlNLS0tStWzdJ0uWXX642bdrolltu0RNPPKG8vDzdf//9Sk9P9yspoqEBAMA0QfLog+eeO34T1EsvvdRn/+zZszVs2DBJ0tSpUxUSEqJrrrnG58Z6PwoNDdXChQs1cuRIpaWlKTo6WkOHDtXEiRP9qoX70PwCcB8aZ3AfGgD/qzbvQ1M8/LeOnTvmpcWOndtJJDQAABjGCpKEJpjQ0AAAYBoaGhuucgIAAMYjoQEAwDTB8bDtoEJCAwAAjEdCAwCAYVgUbEdCAwAAjEdCAwCAaUhobEhoAACA8UhoAAAwDVc52ZDQAAAA45HQAABgGK5ysqOhAQDANEw52TDlBAAAjEdCAwCAYZhysiOhAQAAxiOhAQDANKyhsSGhAQAAxiOhAQDAMBYJjQ0JDQAAMB4JDQAApiGhsaGhAQDAMEw52THlBAAAjEdCAwCAaUhobEhoAACA8UhoAAAwDGto7EhoAACA8UhoAAAwDAmNHQkNAAAwHgkNAACGIaGxo6EBAMA0livQFQQdGppfgLhncgNdQp207dx2gS6hzmqzc3OgSwBgGBoaAAAMw5STHYuCAQCA8UhoAAAwjOVhDc1PkdAAAADjkdAAAGAY1tDYkdAAAADjkdAAAGAYi/vQ2NDQAABgGKac7JhyAgAAxiOhAQDAMFy2bUdCAwAAjEdCAwCAYSwr0BUEHxIaAABgPBIaAAAMwxoaOxIaAABgPBIaAAAMQ0JjR0MDAIBhWBRsx5QTAAAwHgkNAACGYcrJjoQGAAAYj4QGAADD8LRtOxIaAABgPBIaAAAMY3kCXUHwIaEBAADGI6EBAMAwHtbQ2NDQAABgGBYF2zHlBAAAjEdCAwCAYbixnh0JDQAAMB4JDQAAhuHhlHYkNAAAwHgkNAAAGIY1NHYkNAAAwHgkNAAAGIYb69nR0AAAYBhurGfHlBMAADAeDQ0AAIaxLOc2fyxfvlxXXXWVmjRpIpfLpbfeesvn9WHDhsnlcvlsffv29Tnm4MGDGjJkiGJiYhQXF6fhw4erpKTE7zGhoQEAANVSWlqqDh06aObMmSc9pm/fvtq3b593+/vf/+7z+pAhQ7R161YtXrxYCxcu1PLly3X77bf7XQtraAAAMEywLAru16+f+vXrd8pjIiMjlZKScsLXtm/frkWLFmnt2rXq0qWLJOnpp5/WFVdcoSlTpqhJkyZVroWEBgAAeLndbhUXF/tsbre72uf7+OOPlZSUpPPPP18jR47UgQMHvK/l5OQoLi7O28xIUu/evRUSEqI1a9b49XtoaPw08o6h2vHlapUU79Sqle+qa5eOgS6pTmBc/RfVpa2aPPugzln2is7bvkjRvdJsx0Sc00xNZj6ocz/9p1rmvqXmr89QWONE7+uuiHAlPZCuc3NeV8t1C9R4+v0KbRRXi5/CbHxva97F3VP11oI52vVtriqOfa8BA/oEuqSgZFkux7bs7GzFxsb6bNnZ2dWqs2/fvpo3b56WLFmixx9/XMuWLVO/fv1UWVkpScrLy1NSUpLPe8LCwhQfH6+8vDy/fhcNjR+uu26ApkyeoIcfeUpdU/tq46Ztev+9V5SY2CjQpRmNca0eV1Q9ub/4RgUPn3juOrxZYzV75Ukd+2a39gy9R98NHKkDz82X5T7mPSYx64+KvjRVe0c/qt233q2wpEZqMuOB2voIRuN764zo6PratGmbRt31f4Eu5RcrKytLRUVFPltWVla1zjV48GANGDBA7dq108CBA7Vw4UKtXbtWH3/8cc0WLRoav4y5a4T+8tJ8zZ33urZv/0p3po/TkSNHdduwwYEuzWiMa/UcWbFOB6bPVcm/V53w9Uajh6p0+VoVTnlJ7u07Vb57n0o/Wq3Kg0WSpJAG9RU7qI/2P/6Cjq7ZKPe2Hcq770lFdbpA9Tq0qs2PYiS+t85Y9OFHGj/hCb399qJAlxLUnLzKKTIyUjExMT5bZGRkjdR9zjnnKCEhQTt27JAkpaSkqKCgwOeYiooKHTx48KTrbk6GhqaKwsPD1alTey1ZusK7z7IsLVm6Ut26dQ5gZWZjXB3icqnBJb/WsW+/15kvPqpzVr6qZq9O85mWirzgV3JFhOtIzmfefeXf7FH53nzV69g6EFUbg+8tAs1juRzbnLRnzx4dOHBAjRs3liSlpaXp0KFDys3N9R6zdOlSeTwepaam+nVuvxuao0ePauXKldq2bZvttbKyMs2bN++05zjRgiMryJ+FnpAQr7CwMBXkF/rsLyjYr5TkxJO8C6fDuDojtFGcQqLrK/4P16t05Tp9/4f7VPLvVWoy4wFFdW0nSQpLOEOeY8fkOVzq897KwkMKSzgjEGUbg+8tcFxJSYk2bNigDRs2SJK++eYbbdiwQbt27VJJSYnuvvturV69Wt9++62WLFmiq6++Wi1btlSfPsfXRrVu3Vp9+/bViBEj9Omnn+qTTz5RRkaGBg8e7NcVTpKfDc2XX36p1q1bq0ePHmrXrp0uueQS7du3z/t6UVGRbrvtttOe50QLjizPYb8KB3AKruP/yipZmqNDcxfI/fnX+uEvr6v0408Ve0P/ABcH4OdyclGwP9atW6cLL7xQF154oSQpMzNTF154ocaPH6/Q0FBt2rRJAwYM0Hnnnafhw4erc+fOWrFihc8U1iuvvKJWrVqpV69euuKKK9S9e3e98MILfo+JX/ehuffee9W2bVutW7dOhw4d0ujRo3XRRRfp448/VvPmzat8nqysLGVmZvrsO6NRcM/ZFxYeVEVFhZKSE3z2JyUlKi9/f4CqMh/j6ozKQ8Wyyit0bOcun/3Hvt6lqE4XSJIqCn9QSESEQhpG+6Q0oQlxqij8oVbrNQ3fW+C4Sy+99JQzLB9++OFpzxEfH6/58+f/7Fr8SmhWrVql7OxsJSQkqGXLlnr33XfVp08fXXzxxfr666+rfJ4TLThyuYLjJkEnU15ervXrN6nnZd29+1wul3pe1l2rV+ee4p04FcbVIeUVKtvypSJaNPXZHXH2mSrfe3wBnnvrV7KOlat+t47e18PPbqrwJskq27C9Nqs1Dt9bBJqpa2ic5FdCc/ToUYWF/fctLpdLzz33nDIyMnTJJZfUSIcVzKZOf1GzX5qq3PWbtHbtZ/rTqBGKjo7SnLmvBbo0ozGu1eOqX08Rzf87xxzeNEWRrc5RZdFhVezbrx9e/ocaP5mlo+s268iajYru3kXRl3bT7qH3SJI8JUdU9OaHShx3uyqLDstTckRJ99+po59tU9nGzwP1sYzB99YZ0dH11bJlC+/PLc5urg4dLtDBgz9o9+69AawMwc6vhqZVq1Zat26dWrf2vQLimWeekSQNGDCg5ioLQm+88Y4SE+L14PixSklJ1MaNW9X/yptVUFB4+jfjpBjX6ql3wXlqNu8J789J4/4oSSpasFj59z2pkn+vUv5DTyv+9huUeN9IHftmj/be9bDK1m/1vmd/9vOSx1KT6Q/IFRGu0k9yVTDxmVr/LCbie+uMLp07aMm//+H9+ckpD0qS5s57XcP/MCZAVQWf4L6MJjBclh+XF2VnZ2vFihV6//33T/j6nXfeqVmzZsnj8fhdSFjEmX6/Bwikbee2C3QJdVabnZsDXQLgt4pj39fa71rdZJBj5+62903Hzu0kvxoaJ9HQwDQ0NM6hoYGJarOhWdX4GsfO/Zt9/3Ts3E7iadsAABjG38urfwm4UzAAADAeCQ0AAIbxf6Vq3UdCAwAAjEdCAwCAYSyxhuanSGgAAIDxSGgAADCMJyhuuBJcSGgAAIDxSGgAADCMhzU0NiQ0AADAeCQ0AAAYhquc7GhoAAAwDDfWs2PKCQAAGI+EBgAAwzDlZEdCAwAAjEdCAwCAYVhDY0dCAwAAjEdCAwCAYUho7EhoAACA8UhoAAAwDFc52dHQAABgGA/9jA1TTgAAwHgkNAAAGIanbduR0AAAAOOR0AAAYBgr0AUEIRIaAABgPBIaAAAMw4317EhoAACA8UhoAAAwjMfFVU4/RUMDAIBhWBRsx5QTAAAwHgkNAACGYVGwHQkNAAAwHgkNAACG4eGUdiQ0AADAeCQ0AAAYhodT2pHQAAAA45HQAABgGO5DY0dDAwCAYVgUbEdDA1RTm52bA11CnVU07uJAl1BnxU5aEegSAEfQ0AAAYBhurGfHomAAAGA8EhoAAAzDomA7EhoAAGA8EhoAAAzDVU52JDQAAMB4JDQAABiGq5zsaGgAADAMDY0dU04AAMB4JDQAABjGYlGwDQkNAAAwHgkNAACGYQ2NHQkNAAAwHgkNAACGIaGxI6EBAADGI6EBAMAwPJzSjoYGAADD8CwnO6acAACA8UhoAAAwDIuC7UhoAACA8UhoAAAwDAmNHQkNAAAwHgkNAACG4bJtOxIaAABQLcuXL9dVV12lJk2ayOVy6a233vJ53bIsjR8/Xo0bN1ZUVJR69+6tr776yueYgwcPasiQIYqJiVFcXJyGDx+ukpISv2uhoQEAwDAel3ObP0pLS9WhQwfNnDnzhK8/8cQTmjFjhmbNmqU1a9YoOjpaffr0UVlZmfeYIUOGaOvWrVq8eLEWLlyo5cuX6/bbb/d7TJhyAgDAMMGyKLhfv37q16/fCV+zLEvTpk3T/fffr6uvvlqSNG/ePCUnJ+utt97S4MGDtX37di1atEhr165Vly5dJElPP/20rrjiCk2ZMkVNmjSpci0kNAAAwMvtdqu4uNhnc7vdfp/nm2++UV5ennr37u3dFxsbq9TUVOXk5EiScnJyFBcX521mJKl3794KCQnRmjVr/Pp9NDQAABjGcnDLzs5WbGysz5adne13jXl5eZKk5ORkn/3Jycne1/Ly8pSUlOTzelhYmOLj473HVBVTTgAAwCsrK0uZmZk++yIjIwNUTdXR0AAAYBiPgxduR0ZG1kgDk5KSIknKz89X48aNvfvz8/PVsWNH7zEFBQU+76uoqNDBgwe9768qppwAAECNa9GihVJSUrRkyRLvvuLiYq1Zs0ZpaWmSpLS0NB06dEi5ubneY5YuXSqPx6PU1FS/fh8JDQAAhgmWq5xKSkq0Y8cO78/ffPONNmzYoPj4eDVv3lyjR4/WI488ol/96ldq0aKFHnjgATVp0kQDBw6UJLVu3Vp9+/bViBEjNGvWLJWXlysjI0ODBw/26woniYYGAABU07p163TZZZd5f/5x7c3QoUM1Z84c3XPPPSotLdXtt9+uQ4cOqXv37lq0aJHq1avnfc8rr7yijIwM9erVSyEhIbrmmms0Y8YMv2txWZYVFHdQDos4M9AlAAgSReMuDnQJdVbspBWBLqHOqjj2fa39rolnDXHs3OO/e8WxczuJhAYAAMMEy5RTMGFRMAAAMB4JDQAAhvH3mUu/BCQ0AADAeCQ0AAAYxskb65mKhAYAABiPhsZPI+8Yqh1frlZJ8U6tWvmuunbpGOiS6gTG1TmMrX/CL75a9f74qOr/32zVv+d5Rd74Z7kaNfY5JqxzL9W7bbzq3/eyoie+KtWrbztP5E1jFZX5jOo/ME9Rdz+nyEHpcjU8o7Y+hvH43p6akw+nNBUNjR+uu26ApkyeoIcfeUpdU/tq46Ztev+9V5SY2CjQpRmNcXUOY+u/kLNbq2LNv3T0hQdUNvdRKTRU9YbeJ4X/z7NtIiJUuWODyle8ddLzVH6zTe7Xp+nojEy5X50qV3yyIm8Y4/wHqAP43qI6aGj8MOauEfrLS/M1d97r2r79K92ZPk5HjhzVbcMGB7o0ozGuzmFs/ef+6yRVbFgma/8eefJ3yf3mcwqJS1RIkxbeYypyPlD5indUuXvHSc9TkfO+PHt2yCoqlGf3lypf8bZCmraUQkJr42MYje/t6Xkc3ExFQ1NF4eHh6tSpvZYs/e9dNi3L0pKlK9WtW+cAVmY2xtU5jG3NcP1nOsk6WlL9k0RFK6x9d3l2fyl5KmuosrqJ7y2qi6ucqighIV5hYWEqyC/02V9QsF+tzj83QFWZj3F1DmNbA1wuRfQbqsrvPpdVsMfvt4f/9iaFp14uV0Q9Ve7+UmV/e8KBIusWvrdVw1VOdn43NNu3b9fq1auVlpamVq1a6fPPP9f06dPldrt18803q2fPnqc9h9vtltvt9tlnWZZcLu4UBCB4RPT/vUKSmqnspQnVen/5J++qYv1HcsUlKOLSaxR5zZ1y09SgBtDO2Pk15bRo0SJ17NhRY8eO1YUXXqhFixapR48e2rFjh7777jtdfvnlWrp06WnPk52drdjYWJ/N8hyu9oeoDYWFB1VRUaGk5ASf/UlJicrL3x+gqszHuDqHsf15IvrfptDzO6ls9kRZxQerd5Ijh2Ud2CfPzs1yvzFDYed1UkizX9VsoXUM31tUl18NzcSJE3X33XfrwIEDmj17tm666SaNGDFCixcv1pIlS3T33Xdr0qRJpz1PVlaWioqKfDZXSMNqf4jaUF5ervXrN6nnZd29+1wul3pe1l2rV+cGsDKzMa7OYWyrL6L/bQpt3VVlsx+WdaiG/hL9MYEODa+Z89VRfG+rhkXBdn5NOW3dulXz5s2TJF1//fW65ZZbdO2113pfHzJkiGbPnn3a80RGRioyMtJnnwnTTVOnv6jZL01V7vpNWrv2M/1p1AhFR0dpztzXAl2a0RhX5zC2/ou48vcKa3eRyv4+RTp2VK4GsZIkq+yIVFEuSXI1iJWrQZxC4pMlSSHJzSX3UXmKCqWjpQpp2lIhTc6VZ9fnso6WyhWfrIhe18tzIO/4wmCcEt9bVIffa2h+bDxCQkJUr149xcbGel9r2LChioqKaq66IPPGG+8oMSFeD44fq5SURG3cuFX9r7xZBQWFp38zTopxdQ5j67/wX18uSYr6ve+6Gfebz6liwzJJUljX3yrisv/+Yy5q+IM+x1jH3Apr01UhPa+VwiNllRxS5VcbVb7sTamyonY+iMH43p4ei4LtXJZlVXlUOnTooMcff1x9+/aVJG3ZskWtWrVSWNjxvmjFihUaOnSovv76a78LCYs40+/3AKibisZdHOgS6qzYSStOfxCqpeLY97X2uzLPdu6ePE99+6pj53aSXwnNyJEjVVn533sotG3b1uf1Dz74oEpXOQEAgOojn7Hzq6G54447Tvn6Y4899rOKAQAAqA5urAcAgGFMvhrJKTQ0AAAYxmLSyYZnOQEAAOOR0AAAYBimnOxIaAAAgPFIaAAAMAw31rMjoQEAAMYjoQEAwDDkM3YkNAAAwHgkNAAAGIY1NHY0NAAAGIbLtu2YcgIAAMYjoQEAwDA8+sCOhAYAABiPhAYAAMOwhsaOhAYAABiPhAYAAMOwhsaOhAYAABiPhAYAAMOwhsaOhgYAAMN4LKacfoopJwAAYDwSGgAADEM+Y0dCAwAAjEdCAwCAYXjath0JDQAAMB4JDQAAhuHGenYkNAAAwHgkNAAAGIYb69nR0AAAYBgWBdsx5QQAAIxHQgMAgGFYFGxHQgMAAIxHQgMAgGFYFGxHQgMAAIxHQgMAgGEsizU0P0VCAwAAjEdCAwCAYbgPjR0NDQAAhmFRsB1TTgAAwHgkNACCTuykFYEuoc56Pf6SQJeAGsCN9exIaAAAgPFIaAAAMAyLgu1IaAAAgPFIaAAAMAw31rMjoQEAAMYjoQEAwDDch8aOhgYAAMNw2bYdU04AAMB4JDQAABiGy7btSGgAAEC1PPjgg3K5XD5bq1atvK+XlZUpPT1djRo1UoMGDXTNNdcoPz/fkVpoaAAAMIxlWY5t/rrgggu0b98+77Zy5Urva2PGjNG7776rN954Q8uWLdPevXs1aNCgmhwKL6acAACAl9vtltvt9tkXGRmpyMjIEx4fFhamlJQU2/6ioiK99NJLmj9/vnr27ClJmj17tlq3bq3Vq1erW7duNVo3CQ0AAIbxyHJsy87OVmxsrM+WnZ190lq++uorNWnSROecc46GDBmiXbt2SZJyc3NVXl6u3r17e49t1aqVmjdvrpycnBofExIaAADglZWVpczMTJ99J0tnUlNTNWfOHJ1//vnat2+fHnroIV188cXasmWL8vLyFBERobi4OJ/3JCcnKy8vr8brpqEBAMAwTt6H5lTTSz/Vr18/75/bt2+v1NRUnXXWWXr99dcVFRXlVIknxJQTAACG8ViWY9vPERcXp/POO087duxQSkqKjh07pkOHDvkck5+ff8I1Nz8XDQ0AAKgRJSUl2rlzpxo3bqzOnTsrPDxcS5Ys8b7+xRdfaNeuXUpLS6vx382UEwAAhgmW2+qNHTtWV111lc466yzt3btXEyZMUGhoqG688UbFxsZq+PDhyszMVHx8vGJiYjRq1CilpaXV+BVOEg0NAACopj179ujGG2/UgQMHlJiYqO7du2v16tVKTEyUJE2dOlUhISG65ppr5Ha71adPHz377LOO1OKyqnMXHQeERZwZ6BIAoM57Pf6SQJdQZw3Km19rv+uiM3s6du5Pvl/q2LmdxBoaAABgPKacAAAwDA+ntCOhAQAAxiOhAQDAMEGy/DWokNAAAADjkdAAAGAY1tDY0dAAAGAYJ5/lZCqmnAAAgPFIaAAAMAyLgu1IaAAAgPFIaAAAMAyLgu1IaAAAgPFIaAAAMAxraOxIaAAAgPFIaAAAMAxraOxoaAAAMAw31rNjygkAABiPhAYAAMN4WBRsQ0IDAACMR0IDAIBhWENjR0Ljp5F3DNWOL1erpHinVq18V127dAx0SXUC4+ocxtY5jK3/GnVrpbR5Y9Vvw0wNypuvxn27eF9zhYXqgvsHq9dHkzTg65fVb8NMdX56pOolx/mco8/a6RqUN99nOy/jqlr+JAg2NDR+uO66AZoyeYIefuQpdU3tq42btun9915RYmKjQJdmNMbVOYytcxjb6gmrH6mird9pY9Zs22uhURGKa9dCn09doKW//T+t/v1UNTy3sdLmjbUdu+3xN/Reu5HebefL/6qN8oOGx7Ic20xVIw3NL+WOhWPuGqG/vDRfc+e9ru3bv9Kd6eN05MhR3TZscKBLMxrj6hzG1jmMbfXkL92obY+/ob0frLO9VnH4qD65IVvfv7NGJTv36Yf1O7Txvjk6o8M5ijrTt1EsLzkq9/4i71Z5xF1bHwFBqkYamsjISG3fvr0mThW0wsPD1alTey1ZusK7z7IsLVm6Ut26dQ5gZWZjXJ3D2DqHsa09YQ3ry/J4VF50xGf/+aMGqP+259Vz8WP61Z1XyhX6y5pwsBz8z1R+LQrOzMw84f7KykpNmjRJjRod76CfeuqpU57H7XbL7fbtpi3Lksvl8qecWpWQEK+wsDAV5Bf67C8o2K9W558boKrMx7g6h7F1DmNbO0Iiw9X2/hu1e0GOKkqOevfv/MuHOrT5Gx37oUSNup6nC+4brHpJcdr84N8CWG3tMnlqyCl+NTTTpk1Thw4dFBcX57Pfsixt375d0dHRVWpKsrOz9dBDD/nsc4U0kCs0xp9yAAB1lCssVKkv/Ekul7Th3pd9Xtvx/PvePxdv3y1PeYUufGK4tj72qjzHKmq7VAQJvxqaxx57TC+88IKefPJJ9ezZ07s/PDxcc+bMUZs2bap0nqysLFvac0ajVv6UUusKCw+qoqJCSckJPvuTkhKVl78/QFWZj3F1DmPrHMbWWT82M1FNE7Ty2kd90pkTObh+h0LCw1S/WaJKdu6rpSoDy+SpIaf4Nek4btw4vfbaaxo5cqTGjh2r8vLyav3SyMhIxcTE+GzBPN0kSeXl5Vq/fpN6Xtbdu8/lcqnnZd21enVuACszG+PqHMbWOYytc35sZqLPSdHK6x/TsR9KTvueuAvOllXpkbuwuBYqRLDy+8Z6Xbt2VW5urtLT09WlSxe98sorQd+M1JSp01/U7JemKnf9Jq1d+5n+NGqEoqOjNGfua4EuzWiMq3MYW+cwttUTWj9SDVqkeH+Obp6o2AvO0rFDJSrLP6TUv9yluHYtlHPLZLlCQhSZGCtJOnaoRFZ5peI7/0pndDpXhZ9sU3lJmRp1+ZXaTbxZu/65UuVFpYH6WLWONTR21bpTcIMGDTR37ly9+uqr6t27tyorK2u6rqD0xhvvKDEhXg+OH6uUlERt3LhV/a+8WQUFhad/M06KcXUOY+scxrZ6zuh4jnq8+YD35/YTb5EkfffaMm2f8k81+c+N9notneTzvuWDHlbhqu3yHCtXs4Fpaj32GoVGhKt0d4F2PP+Bz7oa/DK5rJ95E5k9e/YoNzdXvXv3VnR0dLXPExZx5s8pAwBQBa/HXxLoEuqsQXnza+13nZNwoWPn/rrwM8fO7aSf/Synpk2bqmnTpjVRCwAAQLXwcEoAAAxjWZ5AlxB0aGgAADCMh8u2bX5Z94oGAAB1EgkNAACG+aU8FNofJDQAAMB4JDQAABiGNTR2JDQAAMB4JDQAABiGNTR2JDQAAMB4JDQAABiGh1Pa0dAAAGAYi0XBNkw5AQAA45HQAABgGBYF25HQAAAA45HQAABgGG6sZ0dCAwAAjEdCAwCAYVhDY0dCAwAAjEdCAwCAYbixnh0NDQAAhmHKyY4pJwAAYDwSGgAADMNl23YkNAAAwHgkNAAAGIY1NHYkNAAAwHgkNAAAGIbLtu1IaAAAgPFIaAAAMIzFVU42NDQAABiGKSc7ppwAAIDxSGgAADAMl23bkdAAAADjkdAAAGAYFgXbkdAAAADjkdAAAGAY1tDYkdAAAADj0dAAAGAYy7Ic26pj5syZOvvss1WvXj2lpqbq008/reFPfHo0NAAAGMZycPPXa6+9pszMTE2YMEHr169Xhw4d1KdPHxUUFPyMT+g/GhoAAODldrtVXFzss7nd7pMe/9RTT2nEiBG67bbb1KZNG82aNUv169fXyy+/XItVS7Lgl7KyMmvChAlWWVlZoEupcxhb5zC2zmFsncG4Bs6ECRNswc2ECRNOeKzb7bZCQ0OtBQsW+Oy/9dZbrQEDBjhf7P9wWRZLpf1RXFys2NhYFRUVKSYmJtDl1CmMrXMYW+cwts5gXAPH7XbbEpnIyEhFRkbajt27d6/OPPNMrVq1Smlpad7999xzj5YtW6Y1a9Y4Xu+PuGwbAAB4nax5CXasoQEAANWSkJCg0NBQ5efn++zPz89XSkpKrdZCQwMAAKolIiJCnTt31pIlS7z7PB6PlixZ4jMFVRuYcvJTZGSkJkyYYGQcF+wYW+cwts5hbJ3BuJojMzNTQ4cOVZcuXfTrX/9a06ZNU2lpqW677bZarYNFwQAA4Gd55plnNHnyZOXl5aljx46aMWOGUlNTa7UGGhoAAGA81tAAAADj0dAAAADj0dAAAADj0dAAAADj0dD4KRgekV7XLF++XFdddZWaNGkil8ult956K9Al1QnZ2dnq2rWrGjZsqKSkJA0cOFBffPFFoMuqE5577jm1b99eMTExiomJUVpamj744INAl1UnTZo0SS6XS6NHjw50KQhyNDR+CJZHpNc1paWl6tChg2bOnBnoUuqUZcuWKT09XatXr9bixYtVXl6uyy+/XKWlpYEuzXhNmzbVpEmTlJubq3Xr1qlnz566+uqrtXXr1kCXVqesXbtWzz//vNq3bx/oUmAALtv2Q2pqqrp27apnnnlG0vG7ITZr1kyjRo3SuHHjAlxd3eByubRgwQINHDgw0KXUOfv371dSUpKWLVumHj16BLqcOic+Pl6TJ0/W8OHDA11KnVBSUqJOnTrp2Wef1SOPPKKOHTtq2rRpgS4LQYyEpoqOHTum3Nxc9e7d27svJCREvXv3Vk5OTgArA6qmqKhI0vG/eFFzKisr9eqrr6q0tLTWb/Vel6Wnp6t///4+/88FToVHH1RRYWGhKisrlZyc7LM/OTlZn3/+eYCqAqrG4/Fo9OjRuuiii9S2bdtAl1MnbN68WWlpaSorK1ODBg20YMECtWnTJtBl1Qmvvvqq1q9fr7Vr1wa6FBiEhgb4BUhPT9eWLVu0cuXKQJdSZ5x//vnasGGDioqK9I9//ENDhw7VsmXLaGp+pt27d+uuu+7S4sWLVa9evUCXA4PQ0FRRMD0iHfBHRkaGFi5cqOXLl6tp06aBLqfOiIiIUMuWLSVJnTt31tq1azV9+nQ9//zzAa7MbLm5uSooKFCnTp28+yorK7V8+XI988wzcrvdCg0NDWCFCFasoamiYHpEOlAVlmUpIyNDCxYs0NKlS9WiRYtAl1SneTweud3uQJdhvF69emnz5s3asGGDd+vSpYuGDBmiDRs20MzgpEho/BAsj0iva0pKSrRjxw7vz9988402bNig+Ph4NW/ePICVmS09PV3z58/X22+/rYYNGyovL0+SFBsbq6ioqABXZ7asrCz169dPzZs31+HDhzV//nx9/PHH+vDDDwNdmvEaNmxoW+cVHR2tRo0asf4Lp0RD44cbbrhB+/fv1/jx472PSF+0aJFtoTD8s27dOl122WXenzMzMyVJQ4cO1Zw5cwJUlfmee+45SdKll17qs3/27NkaNmxY7RdUhxQUFOjWW2/Vvn37FBsbq/bt2+vDDz/Ub3/720CXBvxicR8aAABgPNbQAAAA49HQAAAA49HQAAAA49HQAAAA49HQAAAA49HQAAAA49HQAAAA49HQAAAA49HQAAAA49HQAAAA49HQAAAA4/0/8BSfZ9ipJTsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       295\n",
      "           1       1.00      1.00      1.00       206\n",
      "           2       1.00      0.99      1.00       161\n",
      "           3       1.00      1.00      1.00       213\n",
      "           4       0.98      1.00      0.99       125\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/myenv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw8hzi85m/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw8hzi85m/assets\n",
      "2024-01-10 12:02:40.379965: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-10 12:02:40.379992: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-10 12:02:40.380296: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpw8hzi85m\n",
      "2024-01-10 12:02:40.382117: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-10 12:02:40.382129: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpw8hzi85m\n",
      "2024-01-10 12:02:40.385392: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-01-10 12:02:40.388719: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-10 12:02:40.447027: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpw8hzi85m\n",
      "2024-01-10 12:02:40.464744: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 84451 microseconds.\n",
      "2024-01-10 12:02:40.483581: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 8, Total Ops 19, % non-converted = 42.11 %\n",
      " * 8 ARITH ops\n",
      "\n",
      "- arith.constant:    8 occurrences  (f32: 8)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (uq_8: 2)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17776"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/two_hands_keypoint_classifier/two_hands_keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 397 µs, sys: 52 µs, total: 449 µs\n",
      "Wall time: 372 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.1789527e-08 9.9999750e-01 2.4446829e-06 8.9107749e-11 7.1883814e-09]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
